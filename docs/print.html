<!DOCTYPE HTML>
<html lang="en" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Fern</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "coal" : "rust";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Fern</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="what-is-fern"><a class="header" href="#what-is-fern">What is Fern?</a></h1>
<p>Fern optimizes pipelines built from sequences of function calls. In particular,
Fern <a href="fusion.html"><em>fuses</em></a> function calls, and produces code that evaluates
operations back-to-back on small chunks of data as opposed to entire outputs.
Fern accomplishes this by requiring functions to declare how they produce and
consume data.</p>
<p>Fern's core idea is that that fused code naturally separates concerns: inner
loops handle computation and hardware-specific logic, while outer loops manage
data movement. Fern uses black-box subroutines to perform computations and uses
simple dataflow analysis to generate outer loops.</p>
<p>Our <a href="https://dl.acm.org/doi/10.1145/3729292">paper</a> on <em>Lightweight and
Locality-Aware Composition of Black-Box Subroutines</em> discusses Fern's design
philosophy in detail.</p>
<h3 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h3>
<p>To get started with Fern, take a look at the <a href="install.html">installation</a>
instructions.</p>
<p>The <a href="tutorial/overview.html">tutorial</a> walks through several example Fern programs
to help you understand how it works in practice.</p>
<h3 id="talk"><a class="header" href="#talk">Talk</a></h3>
<p>You can also watch our CppCon talk about Fern. Fern has evolved quite
a bit since then, but the design philosophy at its core has remained
the same.</p>
<div style="text-align: center;">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/pEcOZDRXhNM?si=8q2EeHAD2LNppECr" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="an-introduction-to-operator-fusion"><a class="header" href="#an-introduction-to-operator-fusion">An Introduction to Operator Fusion</a></h1>
<h2 id="a-simple-example"><a class="header" href="#a-simple-example">A Simple Example</a></h2>
<p>Consider a simple function that takes in an array of floats <code>a</code>,
and adds 1 to each element, storing its output in <code>b</code>:</p>
<pre><code class="language-C++">void add_1(float * a, float *b, int N){
    for (int i = 0; i &lt; N; i++){
        b[i] = a[i] + 1;
    }
}
</code></pre>
<p>To perform 2 to elements to an array, we can simply call <code>add_1</code> twice:</p>
<pre><code class="language-C++">    float * a  = (float *) malloc(N * sizeof(float)) 
    float * b  = (float *) malloc(N * sizeof(float)) 
    float * c  = (float *) malloc(N * sizeof(float)) 
    add_1(b, a, N);
    add_1(c, b, N);
</code></pre>
<p>or, we can implement a special  <code>add_2</code> function:</p>
<pre><code class="language-C++">void add_2(float * a, float *b, int N){
    for (int i = 0; i &lt; N; i++){
        b[i] = a[i] + 2;
    }
}
</code></pre>
<p>and simply call it:</p>
<pre><code class="language-C++">    float * a  = (float *) malloc(N * sizeof(float)) 
    float * c  = (float *) malloc(N * sizeof(float)) 
    add_2(c, a, N);
</code></pre>
<p>The <code>add_2</code> function not only uses less memory, requiring no allocation for an
intermediate, it also takes advantage of <em>locality</em>. Each float is loaded once
and all operations are applied immediately, when the data is ready. This
technique of applying a sequence of operations back-to-back on susbets of data
rather than computing entire intermediate outputs is called <strong>operator fusion</strong>.</p>
<p>Traditionally, your favorite compiler runs a fusion pass, bringing computations
into the same outer-loop scope when it can determine that the transformation is
correct. While these passes typically fuse at single data element granularity,
one can also generalize this idea to instead think about fusion happening at
different granularities (4 elements, 8 elements, tiles of data, etc.).</p>
<h2 id="operator-fusion-in-practice"><a class="header" href="#operator-fusion-in-practice">Operator Fusion in Practice</a></h2>
<p>High-performance applications are often built as compositions of function calls,
many sourced from mature, highly optimized libraries like CBLAS.  On Apple’s M3
chip, the fastest implementations of the CBLAS interface can be found in
frameworks such as Accelerate and Arm Performance Libraries.</p>
<blockquote>
<p>CBLAS itself contains several fused interfaces. For example, cblas_sgemm
performs a matrix-matrix multiplication with optional transposition and
scaling, all in a single call.</p>
</blockquote>
<p>Say we want to compute a General Vector Rank Update (GER)
operation expressed as \( A = \alpha (x \times y^T) + A \) where \( A \) is
a matrix, \( x \) and  \( y \) are vectors, \( \alpha \) is a scalar, and
all datatypes are floats. Both Accelerate and ArmPL offer implementations of
this operation, and their performance is pretty close.</p>
<div style="text-align: center;">
  <img src="./images/sger.png" alt="Diagram from PDF" style="width: 300px;" />
</div>
<p>If we were to comupute a slight variant of our computation, an SGERB \( A = \alpha (x
\times y^T) + \beta A \), we have two options. First,
we can use ArmPL’s fused BLAS extension interfaces that include an <code>sgerb_</code> subroutine. Or, as
Accelerate has no fused subroutine, we can compose Accelerate’s <code>cblas_sger</code> and <code>cblas_saxpy</code>
subroutines.</p>
<div style="text-align: center;">
  <img src="./images/sgerb.png" alt="Diagram from PDF" style="width: 300px;" />
</div>
<p>However, the fused ArmPL subroutine is 1.24× (geomean) faster than the composed
Accelerate implementation. Since Accelerate already matched ArmPL’s performance
on GER, the performance difference between the two implementations on GERB is
not due to an under-optimized inner loop or poor instruction selection, but is
rather introduced at the point of composition. ArmPL is able to <em>fuse</em> its
computation, resulting in the difference that we see.</p>
<p>In our trivial example with <code>add_1</code>, we could quickly write a fused
implementation. However, in this case, we are stuck: each routine <code>cblas_sger</code>
and <code>cblas_saxpy</code> likely contains hundereds of lines of hairy,
architecture-specific code that would be time consuming to rewrite and error prone
to modify. Worse, both ArmPL and Accelerate are propriety frameworks. In fact, the
Accelerate library is the only way to target undocumented, Apple-specific
hardware. If our user wants to use this special hardware, they are tied to the
Accelerate library, which does not have extended BLAS kernels like
<code>sgerb_</code>. But, if our user wants to use fused implementations provided in
the BLAS extension interface, they must use ArmPL.</p>
<p>Instead of using naive subroutine calls for Accelerate, the user can use code
generated by Fern, which continues to call Accelerate subroutines, but does so
for small tiles of the output at a time. To see how to do this, head to the
<a href="./tutorial/overview.html">tutorial</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installation"><a class="header" href="#installation">Installation</a></h1>
<blockquote>
<p>Fern is now supported by the Gern repository. Gern adds support for GPUs and
contains Fern-style CPU support. Gern is under 🚧 active development 🚧.</p>
</blockquote>
<p>Fern is an open-source project available at
<a href="https://github.com/manya-bansal/gern">https://github.com/manya-bansal/gern</a>.</p>
<p>It is written in C++20 and requires CMake version 3.30 or higher to build.</p>
<h2 id="getting-the-repository"><a class="header" href="#getting-the-repository">Getting the Repository</a></h2>
<p>First, clone the repository from github.</p>
<pre><code class="language-bash">$ git clone git@github.com:manya-bansal/gern.git
</code></pre>
<h2 id="installing-dependencies"><a class="header" href="#installing-dependencies">Installing Dependencies</a></h2>
<h3 id="vcpkg"><a class="header" href="#vcpkg">VCPKG</a></h3>
<p>Fern uses <a href="https://github.com/microsoft/vcpkg"><code>vcpkg</code></a> to manage its
dependencies. Follow the official guide to download and install <code>vcpkg</code>: <a href="https://learn.microsoft.com/en-us/vcpkg/get_started/get-started?pivots=shell-powershell#1---set-up-vcpkg">Get Started with
vcpkg</a></p>
<p>Once installed, set the <code>VCPKG_ROOT</code> environment variable to point to your
<code>vcpkg</code> directory.</p>
<h3 id="cmake"><a class="header" href="#cmake">CMake</a></h3>
<p>Fern uses <code>cmake</code> as its build system. Before building Fern, ensure that <code>cmake</code>
is installed on your system. Fern requires cmake 3.30 and above.</p>
<p>You can download the latest version of CMake from the official website: <a href="https://cmake.org/download/">CMake
Downloads</a></p>
<h2 id="building-fern"><a class="header" href="#building-fern">Building Fern</a></h2>
<p>Now that <code>VCPKG_ROOT</code> is set and you have downloaded the repository, build the
repository from the <code>gern</code> directory:</p>
<pre><code class="language-bash">$ cmake -DGern_CUDA_ARCH=&lt;89,90..,etc&gt; --preset dev 
$ cmake --build build/dev
</code></pre>
<p>If <code>-DGern_CUDA_ARCH</code> is not set, none of the GPU kernels will be run during
tests.</p>
<h2 id="running-tests"><a class="header" href="#running-tests">Running Tests</a></h2>
<p>To run tests, execute:</p>
<pre><code class="language-bash">$ ctest --test-dir build/dev
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="overview"><a class="header" href="#overview">Overview</a></h1>
<blockquote>
<p>Fern is now supported by the Gern repository. Gern adds support for GPUs and
contains Fern-style CPU support. Gern is under 🚧 active development 🚧.</p>
</blockquote>
<p>The tutorial walks you through different programs in Fern with increasing
complexity. The interface to Fern has changed from the paper, though it is
equally powerful.</p>
<p>As opposed to thinking about an explicit separation between algorithm and
schedule—where the schedule is a meta-program describing how lowering might
proceed—the new interface is a "sketch" of the loop nest the user wants the
generated program to have. This sketch is then deterministically lowered into
imperative code, with the compiler filling in any details that can be
automatically inferred.</p>
<p>The tutorial is organized as follows:</p>
<ol>
<li><a href="tutorial/./1_trivial.html">Making our first function call</a></li>
<li><a href="tutorial/./2_running.html">Running our first function call</a></li>
<li><a href="tutorial/./3_multi_func.html">Writing a Multi-Function Pipeline</a></li>
<li><a href="tutorial/./4_multi_dunc_matrix.html">Understaning Data Structures</a></li>
<li><a href="tutorial/./5_tiling.html">Tiling Programs</a></li>
<li><a href="tutorial/./6_tiling.html">Understanding Legal Tilings</a></li>
<li><a href="tutorial/./7_reductions.html">Tiling Through Reductions</a></li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h2 id="making-a-function-call-in-fern"><a class="header" href="#making-a-function-call-in-fern">Making a Function Call in Fern</a></h2>
<p>The easiest program to write in Fern is one that makes a single function call:</p>
<pre><code class="language-C++">#include "helpers.h"

int main() {

    // Our first, simple program.
    auto a = mk_array("a");
    auto b = mk_array("b");

    // Gern object that represents a function.
    gern::annot::add_1 add_1;

    Composable program = {
    // the () operator calls the function, and 
    // generates a "call site".
        add_1(a, b),
    };

    // The program can now be compiled.
    compile_program(program);
}
</code></pre>
<p>Let's look at the different pieces of the <code>add_1</code> object carefully:</p>
<pre><code class="language-C++">class add_1 : public gern::AbstractFunction {
public:
    add_1()
        : input(new const ArrayCPU("input")),
          output(new const ArrayCPU("output")) {
    }

    /* getAnnotation() returns the data production
     * and consumption pattern of the function.
     * See Tiling Programs in the tutorial for more
     * details if you'd like to skip ahead!
    */
    Annotation getAnnotation() override { 
        Variable x("x");

        return annotate(
            Tileable(x = Expr(0), output["size"], step,
                     Produces::Subset(output, {x, step}),
                     Consumes::Subset(input, {x, step})));
    }

     /* getFunction() returns the "C++" signature of the
      * Function that we ultimately use to generate code. 
     */
    virtual FunctionSignature getFunction() override {
        FunctionSignature f;
        f.name = "library::impl::add_1"; // &lt;-- Name of the Function
        f.args = {Parameter(input), Parameter(output)}; // &lt;-- Parameters of the function 
        // Also contains template arguments which has been left empty.
        return f;
    }

    /**  The file that the function declration lives in, this is included
     *   in the generated file.
     */
    std::vector&lt;std::string&gt; getHeader() override {
        return {
            "cpu-array.h",
        };
    }

protected:
    AbstractDataTypePtr input;
    AbstractDataTypePtr output;
    Variable end{"end"};
    Variable step{"step"};
};
</code></pre>
<p>Given our Fern program and the function definition, when we
compile the program, we simply get a function that makes a
single call (we have not tiled our program yet!):</p>
<pre><code class="language-C++">#include "cassert"
#include "cpu-array.h" // Our include file!

// An automatically generated wrapper function name.
void function_3(library::impl::ArrayCPU&amp; a, library::impl::ArrayCPU&amp; b){
      library::impl::add_1(a, b); // the actual function call!
}
</code></pre>
<p>Fern writes the generated code into a file which can then be included in a
project, and run like normal.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="running-our-trivial-program"><a class="header" href="#running-our-trivial-program">Running our trivial program</a></h1>
<p><a href="tutorial/./1_trivial.html">Part one</a> demonstrated how to write a trivial, single
function program. To run it, we had to figure out where the generated
file lives, include it, compile and then execute it. While this works, it's
still annoying to keep including a file into the project just to
execute it. To avoid this, Fern also provides an interface for
jitting and loading the function pointer, so the code can be compiled
and executed more ergonomically.</p>
<p>In this case, we can consider the program as being split into two parts:
program definition and program execution.</p>
<pre><code class="language-C++">#include "helpers.h"
#include "library/array/impl/cpu-array.h"

int main() {

    // ***** PROGRAM DEFINITION *****
    // Our first, simple program.
    auto a_def = mk_array("input");
    auto b_def = mk_array("output");

    gern::annot::add_1 add_1;

    Composable program = {
        add_1(a_def, b_def),
    };

    // ***** PROGRAM EVALUATION *****
    // Compile turns a runner object which can be
    // used to run the program.
    auto runner = compile_program(program);

    library::impl::ArrayCPU a(10);
    a.ascending();
    library::impl::ArrayCPU b(10);

    // Evaluate the program. The 
    // function takes in a map, and 
    // corresponding names of the inputs and
    // outputs. Fern will wire these up correctly! 
    runner.evaluate({
        {"output", &amp;b},
        {"input", &amp;a},
    });

    // Make sure we got the right answer.
    for (int i = 0; i &lt; 10; i++) {
        std::cout &lt;&lt; "a[" &lt;&lt; i &lt;&lt; "] = " &lt;&lt; a.data[i]
                  &lt;&lt; ", b[" &lt;&lt; i &lt;&lt; "] = " &lt;&lt; b.data[i] &lt;&lt; std::endl;
        assert(a.data[i] + 1 == b.data[i]);
    }
}
</code></pre>
<p>It is worthwhile breaking down what the <code>compile_program</code> helper
is hiding:</p>
<pre><code class="language-C++">inline Runner compile_program(Composable program,
                              std::string name = "program.cpp") {
    Runner runner(program);
    Runner::Options options{
        // Name of the generated file
        .filename = name,
        // Path where the file should be put.
        .prefix = "/home/manya/gern/prez/gern_gen",
        // Paths to include
        .include = " -I /home/manya/gern/prez/library/array/impl"
                   " -I /home/manya/gern/prez/library/matrix/impl",
    };
    // Compile the program!
    runner.compile(options);
    return runner;
}
</code></pre>
<p><code>Runner::Options</code> contains more choices for flags that can be set.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="calling-multiple-functions"><a class="header" href="#calling-multiple-functions">Calling multiple functions</a></h2>
<p>Now that we know how to write and execute Fern pipelines with one function,
let's turn our attention to longer pipelines. Here's our previous pipeline,
but now with one additional function call:</p>
<pre><code class="language-C++">#include "helpers.h"
#include "library/array/impl/cpu-array.h"

int main() {

    // ***** PROGRAM DEFINITION *****
    // Our first, simple program.
    auto input = mk_array("input");
    auto temp = mk_array("temp");
    auto output = mk_array("output");

    gern::annot::add_1 add_1;

    Composable program({
        add_1(input, temp),
        add_1(temp, output), // &lt;--  New Call
    });

    // ***** PROGRAM EVALUATION *****
    library::impl::ArrayCPU a(10);
    a.ascending();
    library::impl::ArrayCPU b(10);

    auto runner = compile_program(program);
    runner.evaluate(
        {
            {"output", &amp;b},
            {"input", &amp;a},
        });

    // SANITY CHECK
    for (int i = 0; i &lt; 10; i++) {
        assert(a.data[i] + 2 == b.data[i]);
    }
}
</code></pre>
<p>As we begin to start writing longer pipelines, there are some rules about writing pipelines
must observe:</p>
<ol>
<li>All data-structures can be assigned to only once.
<blockquote>
<p>This means that we could not used <code>temp</code> again as the output of our second call.</p>
</blockquote>
</li>
<li>All intermediates must be used an input at least once.
<blockquote>
<p>Fern would have thrown an error in the case that <code>temp</code> was computed, but never
used as input.</p>
</blockquote>
</li>
</ol>
<p>There are more rules coming up as we write tiled pipelines!</p>
<p>While our program defintion contains <code>temp</code>, you might have noticed that the program
evaluation does not! Indeed, if we look at the generated code, Fern is allocating it:</p>
<pre><code class="language-C++">void function_5(library::impl::ArrayCPU &amp;input, library::impl::ArrayCPU &amp;output) {
    library::impl::ArrayCPU temp = library::impl::ArrayCPU::allocate(0, output.size);

    library::impl::add_1(input, temp);

    library::impl::add_1(temp, output);

    temp.destroy();
}
</code></pre>
<p>Fern owns all the temporary/intermediate tensors in a pipeline (and will
optimize for reuse of temporaries and hoisting them out). Therefore, only "true"
inputs and the "true" output is passed in.</p>
<p>At this point, you might have a lingering question: how did Fern figure out what
allocate call to make in the first place?</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="matrix-program"><a class="header" href="#matrix-program">Matrix program</a></h1>
<p>The last piece to unpack before we begin fusing programs is the set of data
structures we've been using in our program definitions. Just like the <code>add_1</code>
function, these data structures are also part of the overall program definition
and contain essential information that Fern uses during code generation and
execution.</p>
<p>Let's look at the array object that <code>mk_array</code> produces:</p>
<pre><code class="language-C++">    auto input = mk_array("input");
</code></pre>
<pre><code class="language-C++">class ArrayCPU : public gern::AbstractDataType {
public:
    // Array must have a name!
    ArrayCPU(const std::string &amp;name)
        : name(name) {
    }
    // Get the name to use in codegen. 
    std::string getName() const override {
        return name;
    }

    // Get the type to use in codegen. 
    std::string getType() const override {
        return "library::impl::ArrayCPU";
    }

    // The fields of the array are what we will eventually 
    // use to tile our program! In this represenatation
    // x denotes about the start of a subarray, while len
    // denotes the length of the subarray. Gern attaches
    // no semantic meaning to these fields, it just promises
    // to wire then up correctly! The ordering here does play a role!
    std::vector&lt;Variable&gt; getFields() const override {
        return {x, len};
    }
    // How can gern allocate an array?
    FunctionSignature getAllocateFunction() const override {
        return FunctionSignature{
            .name = "library::impl::ArrayCPU::allocate",
            .args = {x, len},
        };
    }
    // How can gern free an array?
    FunctionSignature getFreeFunction() const override {
        return FunctionSignature{
            .name = "destroy",
            .args = {},
        };
    }
    // If gern has a subarray, how can it insert into a parent array?
    FunctionSignature getInsertFunction() const override {
        return FunctionSignature{
            .name = "insert",
            .args = {x, len},
        };
    }

    // If gern wants to extract a subarray, how can it query it?
    FunctionSignature getQueryFunction() const override {
        return FunctionSignature{
            .name = "query",
            .args = {x, len},
        };
    }

protected:
    std::string name;
    Variable x{"x"};
    Variable len{"len"};
};
</code></pre>
<p>Similar to our array example, we could have instead used a matrix
data structure. Let's take a look at the fieds of the matrix:</p>
<pre><code class="language-C++">  std::vector&lt;Variable&gt; getFields() const override {
        return {x, y, l_x, l_y};
  }
</code></pre>
<p>Here, <code>x</code> and <code>y</code> point at the start of a submatrix, while
<code>l_x</code> and <code>l_y</code> denote its height and width. Similar to the
array, we can write a program that uses the matrix!</p>
<pre><code class="language-C++">#include "helpers.h"
#include "library/matrix/annot/cpu-matrix.h"
#include "library/matrix/impl/cpu-matrix.h"

    int
    main()
{
    // ***** PROGRAM DEFINITION *****
    auto input = mk_matrix("input");
    auto output = mk_matrix("output");
    auto temp = mk_matrix("temp");

    annot::MatrixAddCPU add_1;

    Composable program({
        add_1(input, temp),
        add_1(temp, output),
    });

    // ***** PROGRAM EVALUATION *****
    library::impl::MatrixCPU a(10, 10, 10);
    a.ascending();
    library::impl::MatrixCPU b(10, 10, 10);

    auto runner = compile_program(program);
    runner.evaluate({
        {"input", &amp;a},
        {"output", &amp;b},
    });

    // ***** SANITY CHECK *****
    for (int i = 0; i &lt; a.col; i++)
    {
        for (int j = 0; j &lt; a.row; j++)
        {
            assert(a(i, j) + 2 == b(i, j));
        }
    }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tiling-a-multi-function-program"><a class="header" href="#tiling-a-multi-function-program">Tiling a multi-function program</a></h1>
<p>Finally, we can start rewriting tiling programs
and producing fused variants.</p>
<p>Let's go back to the annotation function that we saw
<a href="tutorial/./1_trivial.html">previously</a>.</p>
<pre><code class="language-C++">   Annotation getAnnotation() override { 
        Variable x("x");
        return annotate(
            // Tilable tells us what dimensions of the output
            // can be tiled.
            Tileable(x = Expr(0), output["size"], step,
                     // Produces indicates what subset (pointed at 
                     // by the fields we saw in the last chapter) 
                     // of the output we are describing.
                     Produces::Subset(output, {x, step}),
                     // What subsets of the input do we need to 
                     // consume to produce the required output subset?
                     Consumes::Subset(input, {x, step})));
    }
</code></pre>
<p>Now to generate a fused version, we simply tile the output's dimension! As expected, only fields marked as tileable can be tiled.</p>
<pre><code class="language-C++">#include "helpers.h"
#include "library/array/impl/cpu-array.h"

using namespace gern;

int main() {

    // ***** PROGRAM DEFINITION *****
    // Our first, simple program.
    auto input = mk_array("input");
    auto temp = mk_array("temp");
    auto output = mk_array("output");
    Variable t("t");

    gern::annot::add_1 add_1;

    Composable program({
        // Tile the output!
        // t indicates what the tile
        // size should be
        Tile(output["size"], t)(
            add_1(input, temp),
            add_1(temp, output)),
    });

    // ***** PROGRAM EVALUATION *****
    library::impl::ArrayCPU a(10);
    a.ascending();
    library::impl::ArrayCPU b(10);
    int64_t t_val = 2;

    auto runner = compile_program(program);
    runner.evaluate(
        {
            {"output", &amp;b},
            {"input", &amp;a},
            {"t", &amp;t_val}, // &lt;-- t must also be provided now!
        });

    // SANITY CHECK
    for (int i = 0; i &lt; 10; i++) {
        assert(a.data[i] + 2 == b.data[i]);
    }
}
</code></pre>
<p>Finally, we can look at the generated tiled program:</p>
<pre><code class="language-C++">void function_7(library::impl::ArrayCPU &amp;input, library::impl::ArrayCPU &amp;output, int64_t t) {
    for (int64_t _gern_x_2_6 = 0; (_gern_x_2_6 &lt; output.size); _gern_x_2_6 = (_gern_x_2_6 + t)) {
        auto _query_output_8 = output.query(_gern_x_2_6, t);

        library::impl::ArrayCPU temp = library::impl::ArrayCPU::allocate(_gern_x_2_6, t);

        auto _query_input_9 = input.query(_gern_x_2_6, t);

        library::impl::add_1(_query_input_9, temp);

        library::impl::add_1(temp, _query_output_8);

        temp.destroy();
    }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="more-tilings"><a class="header" href="#more-tilings">More Tilings</a></h2>
<p>Let's look at more tilings that Gern allows programmers to write:</p>
<pre><code class="language-C++">    // Outputs can be double tiled!
    Composable program({
        // More tiling!
        Tile(output["size"], t)(
            Tile(output["size"], t2)(
                add_1(input, temp),
                add_1(temp, output))),
    });
</code></pre>
<p>The program produces the output, where the computation is tiled twice:</p>
<pre><code class="language-C++">void function_9(library::impl::ArrayCPU &amp;input, library::impl::ArrayCPU &amp;output, int64_t t, int64_t t2) {
    for (int64_t _gern_x_2_6_8 = 0; (_gern_x_2_6_8 &lt; output.size); _gern_x_2_6_8 = (_gern_x_2_6_8 + t)) {
        for (int64_t _gern_x_2_6 = 0; (_gern_x_2_6 &lt; t); _gern_x_2_6 = (_gern_x_2_6 + t2)) {
            auto _query_output_10 = output.query((_gern_x_2_6 + _gern_x_2_6_8), t2);

            library::impl::ArrayCPU temp = library::impl::ArrayCPU::allocate((_gern_x_2_6 + _gern_x_2_6_8), t2);

            auto _query_input_11 = input.query((_gern_x_2_6 + _gern_x_2_6_8), t2);

            library::impl::add_1(_query_input_11, temp);

            library::impl::add_1(temp, _query_output_10);

            temp.destroy();
        }
    }
}
</code></pre>
<p>Nested pipelines can also be written, for example:</p>
<pre><code class="language-C++">    Composable program({
        // More tiling!
        Tile(output["size"], t)(
            Tile(temp["size"], t2)(
                add_1(input, temp)),
            add_1(temp, output)),
    });
</code></pre>
<p>prododuces the following program:</p>
<pre><code class="language-C++">
void function_9(library::impl::ArrayCPU &amp;input, library::impl::ArrayCPU &amp;output, int64_t t, int64_t t2) {
    for (int64_t _gern_x_2_8 = 0; (_gern_x_2_8 &lt; output.size); _gern_x_2_8 = (_gern_x_2_8 + t)) {
        auto _query_output_10 = output.query(_gern_x_2_8, t);

        library::impl::ArrayCPU temp = library::impl::ArrayCPU::allocate(_gern_x_2_8, t);

        for (int64_t _gern_x_4_6 = 0; (_gern_x_4_6 &lt; temp.size); _gern_x_4_6 = (_gern_x_4_6 + t2)) {
            auto _query_temp_11 = temp.query((_gern_x_4_6 + 0), t2);

            auto _query_input_12 = input.query((_gern_x_4_6 + _gern_x_2_8), t2);

            library::impl::add_1(_query_input_12, _query_temp_11);
        }

        library::impl::add_1(temp, _query_output_10);

        temp.destroy();
    }
}
</code></pre>
<p>At each point in the program, Fern has a notion of the data structure the user
intends to produce, and each statement yields a data structure. Tilings are
permitted only for the data structure that is the final output of the current
program scope.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="reductions"><a class="header" href="#reductions">Reductions</a></h1>
<pre><code class="language-C++">#include "helpers.h"
#include "library/array/annot/cpu-array.h"
#include "library/array/impl/cpu-array.h"


Similar to the tiling the output, users can
introduce tiling over a "Reducible" parameter. For instance, the reduction function shown below takes a parameter `k` that specifies how many elements of array `a` contribute to each output element in array `b`:

```C++
inline void reduction(ArrayCPU a, ArrayCPU b, int64_t k) {
    for (int64_t i = 0; i &lt; b.size; i++) {
        for (int64_t j = 0; j &lt; k; j++) {
            b.data[i] += a.data[j];
        }
    }
}
</code></pre>
<p>The annotation for the function indicates that the function can also be
split across <code>k</code>.</p>
<pre><code class="language-C++">return annotate(Tileable(x = Expr(0), output["size"], step,
                        Computes(
                            Produces::Subset(output, {x, step}),
                            Consumes::Subsets(
                                // Indicate a reducible loop
                                Reducible(r = Expr(0), k, reduce,
                                    SubsetObjMany{
                                    SubsetObj(input, {r, reduce})})))));
</code></pre>
<p>The key point is that the reducible parameter must be part of the function interface so that users can tile a reducible loop if needed. A reducible loop is similar to a tilable loop, but with one important distinction: its output is accumulated into a value that is staged outside the loop. This external accumulator enables reduction across tiles or iterations.</p>
<pre><code class="language-C++">using namespace gern;

int main() {
    // ***** PROGRAM DEFINITION *****
    auto input = mk_array("input");
    auto output = mk_array("output");

    gern::annot::reduction reduce;
    Variable len("len");
    Variable tile_size("tile_size");

    Composable program({
        Reduce(len, tile_size)(
            reduce(input, output, len)),
    });

    // ***** PROGRAM EVALUATION *****
    library::impl::ArrayCPU a(10);
    a.ascending();
    library::impl::ArrayCPU b(10);
    int64_t len_val = 10;
    int64_t tile_size_val = 2;

    auto runner = compile_program(program);
    runner.evaluate({
        {"input", &amp;a},
        {"output", &amp;b},
        {"len", &amp;len_val},
        {"tile_size", &amp;tile_size_val},
    }); 
}
</code></pre>
<p>The program produces the following code:</p>
<pre><code class="language-C++">void function_9(library::impl::ArrayCPU &amp;input, library::impl::ArrayCPU &amp;output, int64_t len, int64_t tile_size) {
    for (int64_t _gern_r_1_5 = 0; (_gern_r_1_5 &lt; len); _gern_r_1_5 = (_gern_r_1_5 + tile_size)) {
        auto _query_input_10 = input.query(_gern_r_1_5, tile_size);

        library::impl::reduction(_query_input_10, output, tile_size);
    }
}
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </div>
    </body>
</html>
